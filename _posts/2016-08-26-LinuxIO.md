---
title: "IO多路复用之select, poll, epoll"
tags: [IO,多路复用]
---


最近实习期间正好在做一个系统的架构调整，把原先的多线程系统并为单线程系统，采用IO多路复用来解决IO问题，所以对IO多路复用做了一个比较全面的总结。

### Linux IO模式

在Linux的缓存IO机制中，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间，也就是说每次IO访问都会经历两次拷贝的过程，而这些数据拷贝的过程将给CPU和内存带来非常大的开销。

网络IO实质就是对socket的读取，因此对于socket流而言，每次网络IO一般包括两个步骤：

1. 等待网络数据到达，然后复制到内核缓冲区
2. 把数据从内核缓冲区拷贝到应用进程缓冲区

针对这两个阶段，Linux采用以下五种网络IO模型方案：

- 阻塞IO

默认情况下所有socket都是同步阻塞的，也就是两次拷贝过程整个进程都处于阻塞阶段，不能处理别的网络IO，直到数据成功拷贝到应用进程缓冲区，内核才返回结果，进程重新运行起来。

- 非阻塞IO

轮询（polling）方式，若数据还没有在内核缓冲区准备好，会返回error，直到数据准备好，再拷贝到进程缓冲区，返回成功。

- 多路复用IO

省去了非阻塞IO的轮询步骤，调用select（或poll）可以实现同时对**多个IO端口**监听，当任何一个socket数据准备好了，返回可读然后在调用系统调用将数据从内核拷贝到用户进程。  
实质上每个socket是同步非阻塞的，只不过第一部分阻塞在select/epoll这些系统调用上而不是真正的IO系统调用上。

- 信号驱动IO

首先安装一个信号处理函数，进程不阻塞，当数据拷贝到内核缓冲区之后，进程收到一个信号然后再信号处理函数中调用IO系统调用处理数据。

- 异步IO

IO请求时立即返回，然后进程继续运行，等数据拷贝到用户内存之后给用户进程发送一个信号或执行基于线程的回调函数告知请求已经完成。


### select、poll、epoll详解

**select**

    int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);

select函数监视三种FD（读，写，异常），调用后select阻塞直到有FD就绪或者超时函数返回，然后遍历FD集合找到就绪的描述符。

**缺点：**

1. 每次调用select都要把所有FD集合从用户态拷贝到内核态，这个开销会随FD数目增长线性增长。
2. 每次调用select后都要遍历所有FD来寻找就绪FD，这个开销也会随FD数目增长线性增长。
3. select支持最大FD数仅为1024


**poll**

    int poll (struct pollfd *fds, unsigned int nfds, int timeout);

poll与select类似，不同的地方在于：

1. 没有最大FD限制
2. 使用pollfd来代替select中三个FD集合

pollfd结构如下

    struct pollfd {
    	int fd; /* file descriptor */
    	short events; /* requested events to watch */
    	short revents; /* returned events witnessed */
    };

除此之外其他地方都与select类似。


**epoll**

    int epoll_create(int size)；
    int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；
    int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);

epoll提供了三个接口

1. epoll_create创建一个epoll句柄，size为内核初始分配建议，非最大FD数
2. epoll_ctl给对应FD注册相应的监听类型，epfd为创建句柄返回值
3. epoll_wait等待IO事件

其中epoll\_ctl的OP操作包括添加EPOLL\_CTL\_ADD，删除EPOLL\_CTL\_DEL，修改EPOLL\_CTL_MOD，分别添加、删除和修改对fd的监听事件。

epoll对于select/poll的三个缺点都进行了改进：

1. select在每次调用时都需要将FD集合从用户态拷贝到内核态，而epoll只需要每次注册新事件的时候指定EPOLL\_CTL_ADD，确保了每个FD只会被操作一次，而不会每次重复拷贝
2. 某个FD就绪的时候，通过epoll\_ctl为这个FD注册的监听事件会触发相应的回掉函数将这个就绪的FD加入一个就绪链表，此时调用epoll_wait便可以收到通知，再检查一下就绪链表是否为空即可，无需遍历FD集合
3. epoll没有最大并发连接的限制，所支持的FD上限为最大可以打开文件的数目，与系统内存相关。

### 总结


在FD数量巨大的情况下，epoll在性能上要远优于select/poll，但是在FD数量不多的情况下，可能select/poll性能更优，因为epoll的通知机制需要的函数回调在FD数量少的情况下带来的性能下降也是明显的。
